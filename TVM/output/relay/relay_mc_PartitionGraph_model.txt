def @main(%input: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] span=/quant/QuantizeLinear.input:0:0 */) -> Tensor[(1, 10), float32] {
  @tvmgen_default_DLA_main_0(%input) /* ty=Tensor[(1, 10), float32] */
}

def @tvmgen_default_DLA_main_0(%DLA_0_i0: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] */, Compiler="DLA", Primitive=1, Inline=1, global_symbol="tvmgen_default_DLA_main_0") -> Tensor[(1, 10), float32] {
  %132 = fn (%FunctionVar_0_05: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] */, %FunctionVar_0_15: float32 /* ty=float32 */, %FunctionVar_0_25: int32 /* ty=int32 */, PartitionedFromPattern="qnn.quantize_cast_", Composite="DLA.quantize") -> Tensor[(1, 3, 32, 32), uint8] {
    %131 = qnn.quantize(%FunctionVar_0_05, %FunctionVar_0_15, %FunctionVar_0_25, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 3, 32, 32), uint8] span=/quant/QuantizeLinear:0:0 */;
    cast(%131, dtype="uint8") /* ty=Tensor[(1, 3, 32, 32), uint8] span=/module/conv1/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 3, 32, 32), float32], float32, int32) -> Tensor[(1, 3, 32, 32), uint8] */;
  %133 = %132(%DLA_0_i0, 0.03125f /* ty=float32 span=/quant/Constant_1:0:0 */, 128 /* ty=int32 span=/quant/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 3, 32, 32), uint8] */;
  %134 = fn (%FunctionVar_16_0: Tensor[(1, 3, 32, 32), uint8] /* ty=Tensor[(1, 3, 32, 32), uint8] */, %FunctionVar_16_1: float32 /* ty=float32 */, %FunctionVar_16_2: int32 /* ty=int32 */, %FunctionVar_16_3: Tensor[(32, 3, 3, 3), int8] /* ty=Tensor[(32, 3, 3, 3), int8] */, %FunctionVar_16_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_16_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_16_6: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %FunctionVar_16_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_16_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_16_9: float32 /* ty=float32 */, %FunctionVar_16_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 32, 32, 32), uint8] {
    %124 = qnn.dequantize(%FunctionVar_16_0, %FunctionVar_16_1, %FunctionVar_16_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 3, 32, 32), float32] span=/module/conv1/0/DequantizeLinear:0:0 */;
    %125 = qnn.dequantize(%FunctionVar_16_3, %FunctionVar_16_4, %FunctionVar_16_5, out_dtype="float32", axis=0) /* ty=Tensor[(32, 3, 3, 3), float32] span=/module/conv1/0/DequantizeLinear_1:0:0 */;
    %126 = nn.conv2d(%124, %125, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Conv:0:0 */;
    %127 = qnn.dequantize(%FunctionVar_16_6, %FunctionVar_16_7, %FunctionVar_16_8, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=/module/conv1/0/DequantizeLinear_2:0:0 */;
    %128 = nn.bias_add(%126, %127) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Conv:0:0 */;
    %129 = nn.relu(%128) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Relu:0:0 */;
    %130 = qnn.quantize(%129, %FunctionVar_16_9, %FunctionVar_16_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/conv1/0/QuantizeLinear:0:0 */;
    cast(%130, dtype="uint8") /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 3, 32, 32), uint8], float32, int32, Tensor[(32, 3, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(32), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 32, 32, 32), uint8] */;
  %135 = %134(%133, 0.03125f /* ty=float32 span=/module/conv1/0/Constant:0:0 */, 128 /* ty=int32 span=/module/conv1/0/DequantizeLinear:0:0 */, meta[relay.Constant][0] /* ty=Tensor[(32, 3, 3, 3), int8] span=/module/conv1/0/Constant_2:0:0 */, meta[relay.Constant][1] /* ty=Tensor[(1), float32] span=/module/conv1/0/Constant_3:0:0 */, meta[relay.Constant][2] /* ty=Tensor[(1), int32] span=/module/conv1/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][3] /* ty=Tensor[(32), int32] span=/module/conv1/0/Constant_6:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(1), float32] span=/module/conv1/0/Constant_7:0:0 */, meta[relay.Constant][5] /* ty=Tensor[(1), int32] span=/module/conv1/0/DequantizeLinear_2:0:0 */, 0.015625f /* ty=float32 span=/module/conv1/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/conv1/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 32, 32, 32), uint8] */;
  %136 = fn (%FunctionVar_15_0: Tensor[(1, 32, 32, 32), uint8] /* ty=Tensor[(1, 32, 32, 32), uint8] */, %FunctionVar_15_1: float32 /* ty=float32 */, %FunctionVar_15_2: int32 /* ty=int32 */, %FunctionVar_15_3: Tensor[(32, 1, 3, 3), int8] /* ty=Tensor[(32, 1, 3, 3), int8] */, %FunctionVar_15_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_15_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_15_6: Tensor[(32), int32] /* ty=Tensor[(32), int32] */, %FunctionVar_15_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_15_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_15_9: float32 /* ty=float32 */, %FunctionVar_15_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 32, 32, 32), uint8] {
    %117 = qnn.dequantize(%FunctionVar_15_0, %FunctionVar_15_1, %FunctionVar_15_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/DequantizeLinear:0:0 */;
    %118 = qnn.dequantize(%FunctionVar_15_3, %FunctionVar_15_4, %FunctionVar_15_5, out_dtype="float32", axis=0) /* ty=Tensor[(32, 1, 3, 3), float32] span=/module/layers/0/depthwise/0/DequantizeLinear_1:0:0 */;
    %119 = nn.conv2d(%117, %118, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Conv:0:0 */;
    %120 = qnn.dequantize(%FunctionVar_15_6, %FunctionVar_15_7, %FunctionVar_15_8, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=/module/layers/0/depthwise/0/DequantizeLinear_2:0:0 */;
    %121 = nn.bias_add(%119, %120) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Conv:0:0 */;
    %122 = nn.relu(%121) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Relu:0:0 */;
    %123 = qnn.quantize(%122, %FunctionVar_15_9, %FunctionVar_15_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/depthwise/0/QuantizeLinear:0:0 */;
    cast(%123, dtype="uint8") /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 32), uint8], float32, int32, Tensor[(32, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(32), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 32, 32, 32), uint8] */;
  %137 = %136(%135, 0.015625f /* ty=float32 span=/module/layers/0/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/0/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][6] /* ty=Tensor[(32, 1, 3, 3), int8] span=/module/layers/0/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][7] /* ty=Tensor[(1), float32] span=/module/layers/0/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(1), int32] span=/module/layers/0/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][9] /* ty=Tensor[(32), int32] span=/module/layers/0/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(1), float32] span=/module/layers/0/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(1), int32] span=/module/layers/0/depthwise/0/DequantizeLinear_2:0:0 */, 0.0078125f /* ty=float32 span=/module/layers/0/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/0/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 32, 32, 32), uint8] */;
  %138 = fn (%FunctionVar_14_0: Tensor[(1, 32, 32, 32), uint8] /* ty=Tensor[(1, 32, 32, 32), uint8] */, %FunctionVar_14_1: float32 /* ty=float32 */, %FunctionVar_14_2: int32 /* ty=int32 */, %FunctionVar_14_3: Tensor[(64, 32, 1, 1), int8] /* ty=Tensor[(64, 32, 1, 1), int8] */, %FunctionVar_14_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_14_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_14_6: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %FunctionVar_14_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_14_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_14_9: float32 /* ty=float32 */, %FunctionVar_14_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 64, 32, 32), uint8] {
    %110 = qnn.dequantize(%FunctionVar_14_0, %FunctionVar_14_1, %FunctionVar_14_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/pointwise/0/DequantizeLinear:0:0 */;
    %111 = qnn.dequantize(%FunctionVar_14_3, %FunctionVar_14_4, %FunctionVar_14_5, out_dtype="float32", axis=0) /* ty=Tensor[(64, 32, 1, 1), float32] span=/module/layers/0/pointwise/0/DequantizeLinear_1:0:0 */;
    %112 = nn.conv2d(%110, %111, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Conv:0:0 */;
    %113 = qnn.dequantize(%FunctionVar_14_6, %FunctionVar_14_7, %FunctionVar_14_8, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=/module/layers/0/pointwise/0/DequantizeLinear_2:0:0 */;
    %114 = nn.bias_add(%112, %113) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Conv:0:0 */;
    %115 = nn.relu(%114) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Relu:0:0 */;
    %116 = qnn.quantize(%115, %FunctionVar_14_9, %FunctionVar_14_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 64, 32, 32), uint8] span=/module/layers/0/pointwise/0/QuantizeLinear:0:0 */;
    cast(%116, dtype="uint8") /* ty=Tensor[(1, 64, 32, 32), uint8] span=/module/layers/1/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 32, 32, 32), uint8], float32, int32, Tensor[(64, 32, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(64), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 64, 32, 32), uint8] */;
  %139 = %138(%137, 0.0078125f /* ty=float32 span=/module/layers/0/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/0/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][12] /* ty=Tensor[(64, 32, 1, 1), int8] span=/module/layers/0/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][13] /* ty=Tensor[(1), float32] span=/module/layers/0/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(1), int32] span=/module/layers/0/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][15] /* ty=Tensor[(64), int32] span=/module/layers/0/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(1), float32] span=/module/layers/0/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(1), int32] span=/module/layers/0/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/0/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/0/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 64, 32, 32), uint8] */;
  %140 = fn (%FunctionVar_13_0: Tensor[(1, 64, 32, 32), uint8] /* ty=Tensor[(1, 64, 32, 32), uint8] */, %FunctionVar_13_1: float32 /* ty=float32 */, %FunctionVar_13_2: int32 /* ty=int32 */, %FunctionVar_13_3: Tensor[(64, 1, 3, 3), int8] /* ty=Tensor[(64, 1, 3, 3), int8] */, %FunctionVar_13_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_13_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_13_6: Tensor[(64), int32] /* ty=Tensor[(64), int32] */, %FunctionVar_13_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_13_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_13_9: float32 /* ty=float32 */, %FunctionVar_13_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 64, 16, 16), uint8] {
    %103 = qnn.dequantize(%FunctionVar_13_0, %FunctionVar_13_1, %FunctionVar_13_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/1/depthwise/0/DequantizeLinear:0:0 */;
    %104 = qnn.dequantize(%FunctionVar_13_3, %FunctionVar_13_4, %FunctionVar_13_5, out_dtype="float32", axis=0) /* ty=Tensor[(64, 1, 3, 3), float32] span=/module/layers/1/depthwise/0/DequantizeLinear_1:0:0 */;
    %105 = nn.conv2d(%103, %104, strides=[2, 2], padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Conv:0:0 */;
    %106 = qnn.dequantize(%FunctionVar_13_6, %FunctionVar_13_7, %FunctionVar_13_8, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=/module/layers/1/depthwise/0/DequantizeLinear_2:0:0 */;
    %107 = nn.bias_add(%105, %106) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Conv:0:0 */;
    %108 = nn.relu(%107) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Relu:0:0 */;
    %109 = qnn.quantize(%108, %FunctionVar_13_9, %FunctionVar_13_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 64, 16, 16), uint8] span=/module/layers/1/depthwise/0/QuantizeLinear:0:0 */;
    cast(%109, dtype="uint8") /* ty=Tensor[(1, 64, 16, 16), uint8] span=/module/layers/1/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 64, 32, 32), uint8], float32, int32, Tensor[(64, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(64), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 64, 16, 16), uint8] */;
  %141 = %140(%139, 0.00390625f /* ty=float32 span=/module/layers/1/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/1/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][18] /* ty=Tensor[(64, 1, 3, 3), int8] span=/module/layers/1/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][19] /* ty=Tensor[(1), float32] span=/module/layers/1/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][20] /* ty=Tensor[(1), int32] span=/module/layers/1/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][21] /* ty=Tensor[(64), int32] span=/module/layers/1/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][22] /* ty=Tensor[(1), float32] span=/module/layers/1/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][23] /* ty=Tensor[(1), int32] span=/module/layers/1/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/1/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/1/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 64, 16, 16), uint8] */;
  %142 = fn (%FunctionVar_12_0: Tensor[(1, 64, 16, 16), uint8] /* ty=Tensor[(1, 64, 16, 16), uint8] */, %FunctionVar_12_1: float32 /* ty=float32 */, %FunctionVar_12_2: int32 /* ty=int32 */, %FunctionVar_12_3: Tensor[(128, 64, 1, 1), int8] /* ty=Tensor[(128, 64, 1, 1), int8] */, %FunctionVar_12_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_12_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_12_6: Tensor[(128), int32] /* ty=Tensor[(128), int32] */, %FunctionVar_12_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_12_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_12_9: float32 /* ty=float32 */, %FunctionVar_12_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 128, 16, 16), uint8] {
    %96 = qnn.dequantize(%FunctionVar_12_0, %FunctionVar_12_1, %FunctionVar_12_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/pointwise/0/DequantizeLinear:0:0 */;
    %97 = qnn.dequantize(%FunctionVar_12_3, %FunctionVar_12_4, %FunctionVar_12_5, out_dtype="float32", axis=0) /* ty=Tensor[(128, 64, 1, 1), float32] span=/module/layers/1/pointwise/0/DequantizeLinear_1:0:0 */;
    %98 = nn.conv2d(%96, %97, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Conv:0:0 */;
    %99 = qnn.dequantize(%FunctionVar_12_6, %FunctionVar_12_7, %FunctionVar_12_8, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/1/pointwise/0/DequantizeLinear_2:0:0 */;
    %100 = nn.bias_add(%98, %99) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Conv:0:0 */;
    %101 = nn.relu(%100) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Relu:0:0 */;
    %102 = qnn.quantize(%101, %FunctionVar_12_9, %FunctionVar_12_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/1/pointwise/0/QuantizeLinear:0:0 */;
    cast(%102, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 64, 16, 16), uint8], float32, int32, Tensor[(128, 64, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(128), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 128, 16, 16), uint8] */;
  %143 = %142(%141, 0.00390625f /* ty=float32 span=/module/layers/1/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/1/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][24] /* ty=Tensor[(128, 64, 1, 1), int8] span=/module/layers/1/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][25] /* ty=Tensor[(1), float32] span=/module/layers/1/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][26] /* ty=Tensor[(1), int32] span=/module/layers/1/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][27] /* ty=Tensor[(128), int32] span=/module/layers/1/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][28] /* ty=Tensor[(1), float32] span=/module/layers/1/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][29] /* ty=Tensor[(1), int32] span=/module/layers/1/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/1/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/1/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 128, 16, 16), uint8] */;
  %144 = fn (%FunctionVar_11_0: Tensor[(1, 128, 16, 16), uint8] /* ty=Tensor[(1, 128, 16, 16), uint8] */, %FunctionVar_11_1: float32 /* ty=float32 */, %FunctionVar_11_2: int32 /* ty=int32 */, %FunctionVar_11_3: Tensor[(128, 1, 3, 3), int8] /* ty=Tensor[(128, 1, 3, 3), int8] */, %FunctionVar_11_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_11_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_11_6: Tensor[(128), int32] /* ty=Tensor[(128), int32] */, %FunctionVar_11_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_11_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_11_9: float32 /* ty=float32 */, %FunctionVar_11_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 128, 16, 16), uint8] {
    %89 = qnn.dequantize(%FunctionVar_11_0, %FunctionVar_11_1, %FunctionVar_11_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/DequantizeLinear:0:0 */;
    %90 = qnn.dequantize(%FunctionVar_11_3, %FunctionVar_11_4, %FunctionVar_11_5, out_dtype="float32", axis=0) /* ty=Tensor[(128, 1, 3, 3), float32] span=/module/layers/2/depthwise/0/DequantizeLinear_1:0:0 */;
    %91 = nn.conv2d(%89, %90, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Conv:0:0 */;
    %92 = qnn.dequantize(%FunctionVar_11_6, %FunctionVar_11_7, %FunctionVar_11_8, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/2/depthwise/0/DequantizeLinear_2:0:0 */;
    %93 = nn.bias_add(%91, %92) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Conv:0:0 */;
    %94 = nn.relu(%93) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Relu:0:0 */;
    %95 = qnn.quantize(%94, %FunctionVar_11_9, %FunctionVar_11_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/depthwise/0/QuantizeLinear:0:0 */;
    cast(%95, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 128, 16, 16), uint8], float32, int32, Tensor[(128, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(128), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 128, 16, 16), uint8] */;
  %145 = %144(%143, 0.00390625f /* ty=float32 span=/module/layers/2/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/2/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][30] /* ty=Tensor[(128, 1, 3, 3), int8] span=/module/layers/2/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][31] /* ty=Tensor[(1), float32] span=/module/layers/2/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][32] /* ty=Tensor[(1), int32] span=/module/layers/2/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][33] /* ty=Tensor[(128), int32] span=/module/layers/2/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][34] /* ty=Tensor[(1), float32] span=/module/layers/2/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][35] /* ty=Tensor[(1), int32] span=/module/layers/2/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/2/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/2/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 128, 16, 16), uint8] */;
  %146 = fn (%FunctionVar_10_0: Tensor[(1, 128, 16, 16), uint8] /* ty=Tensor[(1, 128, 16, 16), uint8] */, %FunctionVar_10_1: float32 /* ty=float32 */, %FunctionVar_10_2: int32 /* ty=int32 */, %FunctionVar_10_3: Tensor[(128, 128, 1, 1), int8] /* ty=Tensor[(128, 128, 1, 1), int8] */, %FunctionVar_10_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_10_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_10_6: Tensor[(128), int32] /* ty=Tensor[(128), int32] */, %FunctionVar_10_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_10_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_10_9: float32 /* ty=float32 */, %FunctionVar_10_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 128, 16, 16), uint8] {
    %82 = qnn.dequantize(%FunctionVar_10_0, %FunctionVar_10_1, %FunctionVar_10_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/DequantizeLinear:0:0 */;
    %83 = qnn.dequantize(%FunctionVar_10_3, %FunctionVar_10_4, %FunctionVar_10_5, out_dtype="float32", axis=0) /* ty=Tensor[(128, 128, 1, 1), float32] span=/module/layers/2/pointwise/0/DequantizeLinear_1:0:0 */;
    %84 = nn.conv2d(%82, %83, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Conv:0:0 */;
    %85 = qnn.dequantize(%FunctionVar_10_6, %FunctionVar_10_7, %FunctionVar_10_8, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/2/pointwise/0/DequantizeLinear_2:0:0 */;
    %86 = nn.bias_add(%84, %85) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Conv:0:0 */;
    %87 = nn.relu(%86) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Relu:0:0 */;
    %88 = qnn.quantize(%87, %FunctionVar_10_9, %FunctionVar_10_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/pointwise/0/QuantizeLinear:0:0 */;
    cast(%88, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/3/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 128, 16, 16), uint8], float32, int32, Tensor[(128, 128, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(128), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 128, 16, 16), uint8] */;
  %147 = %146(%145, 0.00390625f /* ty=float32 span=/module/layers/2/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/2/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][36] /* ty=Tensor[(128, 128, 1, 1), int8] span=/module/layers/2/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][37] /* ty=Tensor[(1), float32] span=/module/layers/2/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][38] /* ty=Tensor[(1), int32] span=/module/layers/2/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][39] /* ty=Tensor[(128), int32] span=/module/layers/2/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][40] /* ty=Tensor[(1), float32] span=/module/layers/2/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][41] /* ty=Tensor[(1), int32] span=/module/layers/2/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/2/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/2/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 128, 16, 16), uint8] */;
  %148 = fn (%FunctionVar_9_0: Tensor[(1, 128, 16, 16), uint8] /* ty=Tensor[(1, 128, 16, 16), uint8] */, %FunctionVar_9_1: float32 /* ty=float32 */, %FunctionVar_9_2: int32 /* ty=int32 */, %FunctionVar_9_3: Tensor[(128, 1, 3, 3), int8] /* ty=Tensor[(128, 1, 3, 3), int8] */, %FunctionVar_9_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_9_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_9_6: Tensor[(128), int32] /* ty=Tensor[(128), int32] */, %FunctionVar_9_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_9_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_9_9: float32 /* ty=float32 */, %FunctionVar_9_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 128, 8, 8), uint8] {
    %75 = qnn.dequantize(%FunctionVar_9_0, %FunctionVar_9_1, %FunctionVar_9_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/3/depthwise/0/DequantizeLinear:0:0 */;
    %76 = qnn.dequantize(%FunctionVar_9_3, %FunctionVar_9_4, %FunctionVar_9_5, out_dtype="float32", axis=0) /* ty=Tensor[(128, 1, 3, 3), float32] span=/module/layers/3/depthwise/0/DequantizeLinear_1:0:0 */;
    %77 = nn.conv2d(%75, %76, strides=[2, 2], padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Conv:0:0 */;
    %78 = qnn.dequantize(%FunctionVar_9_6, %FunctionVar_9_7, %FunctionVar_9_8, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/3/depthwise/0/DequantizeLinear_2:0:0 */;
    %79 = nn.bias_add(%77, %78) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Conv:0:0 */;
    %80 = nn.relu(%79) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Relu:0:0 */;
    %81 = qnn.quantize(%80, %FunctionVar_9_9, %FunctionVar_9_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 8, 8), uint8] span=/module/layers/3/depthwise/0/QuantizeLinear:0:0 */;
    cast(%81, dtype="uint8") /* ty=Tensor[(1, 128, 8, 8), uint8] span=/module/layers/3/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 128, 16, 16), uint8], float32, int32, Tensor[(128, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(128), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 128, 8, 8), uint8] */;
  %149 = %148(%147, 0.00390625f /* ty=float32 span=/module/layers/3/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/3/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][42] /* ty=Tensor[(128, 1, 3, 3), int8] span=/module/layers/3/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][43] /* ty=Tensor[(1), float32] span=/module/layers/3/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][44] /* ty=Tensor[(1), int32] span=/module/layers/3/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][45] /* ty=Tensor[(128), int32] span=/module/layers/3/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][46] /* ty=Tensor[(1), float32] span=/module/layers/3/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][47] /* ty=Tensor[(1), int32] span=/module/layers/3/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/3/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/3/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 128, 8, 8), uint8] */;
  %150 = fn (%FunctionVar_8_0: Tensor[(1, 128, 8, 8), uint8] /* ty=Tensor[(1, 128, 8, 8), uint8] */, %FunctionVar_8_1: float32 /* ty=float32 */, %FunctionVar_8_2: int32 /* ty=int32 */, %FunctionVar_8_3: Tensor[(256, 128, 1, 1), int8] /* ty=Tensor[(256, 128, 1, 1), int8] */, %FunctionVar_8_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_8_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_8_6: Tensor[(256), int32] /* ty=Tensor[(256), int32] */, %FunctionVar_8_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_8_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_8_9: float32 /* ty=float32 */, %FunctionVar_8_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 256, 8, 8), uint8] {
    %68 = qnn.dequantize(%FunctionVar_8_0, %FunctionVar_8_1, %FunctionVar_8_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/pointwise/0/DequantizeLinear:0:0 */;
    %69 = qnn.dequantize(%FunctionVar_8_3, %FunctionVar_8_4, %FunctionVar_8_5, out_dtype="float32", axis=0) /* ty=Tensor[(256, 128, 1, 1), float32] span=/module/layers/3/pointwise/0/DequantizeLinear_1:0:0 */;
    %70 = nn.conv2d(%68, %69, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Conv:0:0 */;
    %71 = qnn.dequantize(%FunctionVar_8_6, %FunctionVar_8_7, %FunctionVar_8_8, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/3/pointwise/0/DequantizeLinear_2:0:0 */;
    %72 = nn.bias_add(%70, %71) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Conv:0:0 */;
    %73 = nn.relu(%72) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Relu:0:0 */;
    %74 = qnn.quantize(%73, %FunctionVar_8_9, %FunctionVar_8_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/3/pointwise/0/QuantizeLinear:0:0 */;
    cast(%74, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 128, 8, 8), uint8], float32, int32, Tensor[(256, 128, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(256), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 256, 8, 8), uint8] */;
  %151 = %150(%149, 0.00390625f /* ty=float32 span=/module/layers/3/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/3/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][48] /* ty=Tensor[(256, 128, 1, 1), int8] span=/module/layers/3/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][49] /* ty=Tensor[(1), float32] span=/module/layers/3/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][50] /* ty=Tensor[(1), int32] span=/module/layers/3/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][51] /* ty=Tensor[(256), int32] span=/module/layers/3/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][52] /* ty=Tensor[(1), float32] span=/module/layers/3/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][53] /* ty=Tensor[(1), int32] span=/module/layers/3/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/3/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/3/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 256, 8, 8), uint8] */;
  %152 = fn (%FunctionVar_7_0: Tensor[(1, 256, 8, 8), uint8] /* ty=Tensor[(1, 256, 8, 8), uint8] */, %FunctionVar_7_1: float32 /* ty=float32 */, %FunctionVar_7_2: int32 /* ty=int32 */, %FunctionVar_7_3: Tensor[(256, 1, 3, 3), int8] /* ty=Tensor[(256, 1, 3, 3), int8] */, %FunctionVar_7_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_7_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_7_6: Tensor[(256), int32] /* ty=Tensor[(256), int32] */, %FunctionVar_7_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_7_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_7_9: float32 /* ty=float32 */, %FunctionVar_7_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 256, 8, 8), uint8] {
    %61 = qnn.dequantize(%FunctionVar_7_0, %FunctionVar_7_1, %FunctionVar_7_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/DequantizeLinear:0:0 */;
    %62 = qnn.dequantize(%FunctionVar_7_3, %FunctionVar_7_4, %FunctionVar_7_5, out_dtype="float32", axis=0) /* ty=Tensor[(256, 1, 3, 3), float32] span=/module/layers/4/depthwise/0/DequantizeLinear_1:0:0 */;
    %63 = nn.conv2d(%61, %62, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Conv:0:0 */;
    %64 = qnn.dequantize(%FunctionVar_7_6, %FunctionVar_7_7, %FunctionVar_7_8, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/4/depthwise/0/DequantizeLinear_2:0:0 */;
    %65 = nn.bias_add(%63, %64) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Conv:0:0 */;
    %66 = nn.relu(%65) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Relu:0:0 */;
    %67 = qnn.quantize(%66, %FunctionVar_7_9, %FunctionVar_7_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/depthwise/0/QuantizeLinear:0:0 */;
    cast(%67, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 256, 8, 8), uint8], float32, int32, Tensor[(256, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(256), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 256, 8, 8), uint8] */;
  %153 = %152(%151, 0.00390625f /* ty=float32 span=/module/layers/4/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/4/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][54] /* ty=Tensor[(256, 1, 3, 3), int8] span=/module/layers/4/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][55] /* ty=Tensor[(1), float32] span=/module/layers/4/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][56] /* ty=Tensor[(1), int32] span=/module/layers/4/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][57] /* ty=Tensor[(256), int32] span=/module/layers/4/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][58] /* ty=Tensor[(1), float32] span=/module/layers/4/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][59] /* ty=Tensor[(1), int32] span=/module/layers/4/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/4/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/4/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 256, 8, 8), uint8] */;
  %154 = fn (%FunctionVar_6_0: Tensor[(1, 256, 8, 8), uint8] /* ty=Tensor[(1, 256, 8, 8), uint8] */, %FunctionVar_6_1: float32 /* ty=float32 */, %FunctionVar_6_2: int32 /* ty=int32 */, %FunctionVar_6_3: Tensor[(256, 256, 1, 1), int8] /* ty=Tensor[(256, 256, 1, 1), int8] */, %FunctionVar_6_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_6_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_6_6: Tensor[(256), int32] /* ty=Tensor[(256), int32] */, %FunctionVar_6_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_6_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_6_9: float32 /* ty=float32 */, %FunctionVar_6_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 256, 8, 8), uint8] {
    %54 = qnn.dequantize(%FunctionVar_6_0, %FunctionVar_6_1, %FunctionVar_6_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/DequantizeLinear:0:0 */;
    %55 = qnn.dequantize(%FunctionVar_6_3, %FunctionVar_6_4, %FunctionVar_6_5, out_dtype="float32", axis=0) /* ty=Tensor[(256, 256, 1, 1), float32] span=/module/layers/4/pointwise/0/DequantizeLinear_1:0:0 */;
    %56 = nn.conv2d(%54, %55, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Conv:0:0 */;
    %57 = qnn.dequantize(%FunctionVar_6_6, %FunctionVar_6_7, %FunctionVar_6_8, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/4/pointwise/0/DequantizeLinear_2:0:0 */;
    %58 = nn.bias_add(%56, %57) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Conv:0:0 */;
    %59 = nn.relu(%58) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Relu:0:0 */;
    %60 = qnn.quantize(%59, %FunctionVar_6_9, %FunctionVar_6_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/pointwise/0/QuantizeLinear:0:0 */;
    cast(%60, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/5/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 256, 8, 8), uint8], float32, int32, Tensor[(256, 256, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(256), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 256, 8, 8), uint8] */;
  %155 = %154(%153, 0.00390625f /* ty=float32 span=/module/layers/4/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/4/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][60] /* ty=Tensor[(256, 256, 1, 1), int8] span=/module/layers/4/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][61] /* ty=Tensor[(1), float32] span=/module/layers/4/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][62] /* ty=Tensor[(1), int32] span=/module/layers/4/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][63] /* ty=Tensor[(256), int32] span=/module/layers/4/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][64] /* ty=Tensor[(1), float32] span=/module/layers/4/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][65] /* ty=Tensor[(1), int32] span=/module/layers/4/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/4/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/4/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 256, 8, 8), uint8] */;
  %156 = fn (%FunctionVar_5_0: Tensor[(1, 256, 8, 8), uint8] /* ty=Tensor[(1, 256, 8, 8), uint8] */, %FunctionVar_5_1: float32 /* ty=float32 */, %FunctionVar_5_2: int32 /* ty=int32 */, %FunctionVar_5_3: Tensor[(256, 1, 3, 3), int8] /* ty=Tensor[(256, 1, 3, 3), int8] */, %FunctionVar_5_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_5_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_5_6: Tensor[(256), int32] /* ty=Tensor[(256), int32] */, %FunctionVar_5_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_5_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_5_9: float32 /* ty=float32 */, %FunctionVar_5_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 256, 4, 4), uint8] {
    %47 = qnn.dequantize(%FunctionVar_5_0, %FunctionVar_5_1, %FunctionVar_5_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/5/depthwise/0/DequantizeLinear:0:0 */;
    %48 = qnn.dequantize(%FunctionVar_5_3, %FunctionVar_5_4, %FunctionVar_5_5, out_dtype="float32", axis=0) /* ty=Tensor[(256, 1, 3, 3), float32] span=/module/layers/5/depthwise/0/DequantizeLinear_1:0:0 */;
    %49 = nn.conv2d(%47, %48, strides=[2, 2], padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Conv:0:0 */;
    %50 = qnn.dequantize(%FunctionVar_5_6, %FunctionVar_5_7, %FunctionVar_5_8, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/5/depthwise/0/DequantizeLinear_2:0:0 */;
    %51 = nn.bias_add(%49, %50) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Conv:0:0 */;
    %52 = nn.relu(%51) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Relu:0:0 */;
    %53 = qnn.quantize(%52, %FunctionVar_5_9, %FunctionVar_5_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 4, 4), uint8] span=/module/layers/5/depthwise/0/QuantizeLinear:0:0 */;
    cast(%53, dtype="uint8") /* ty=Tensor[(1, 256, 4, 4), uint8] span=/module/layers/5/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 256, 8, 8), uint8], float32, int32, Tensor[(256, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(256), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 256, 4, 4), uint8] */;
  %157 = %156(%155, 0.00390625f /* ty=float32 span=/module/layers/5/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/5/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][66] /* ty=Tensor[(256, 1, 3, 3), int8] span=/module/layers/5/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][67] /* ty=Tensor[(1), float32] span=/module/layers/5/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][68] /* ty=Tensor[(1), int32] span=/module/layers/5/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][69] /* ty=Tensor[(256), int32] span=/module/layers/5/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][70] /* ty=Tensor[(1), float32] span=/module/layers/5/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][71] /* ty=Tensor[(1), int32] span=/module/layers/5/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/5/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/5/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 256, 4, 4), uint8] */;
  %158 = fn (%FunctionVar_4_0: Tensor[(1, 256, 4, 4), uint8] /* ty=Tensor[(1, 256, 4, 4), uint8] */, %FunctionVar_4_1: float32 /* ty=float32 */, %FunctionVar_4_2: int32 /* ty=int32 */, %FunctionVar_4_3: Tensor[(512, 256, 1, 1), int8] /* ty=Tensor[(512, 256, 1, 1), int8] */, %FunctionVar_4_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_4_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_4_6: Tensor[(512), int32] /* ty=Tensor[(512), int32] */, %FunctionVar_4_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_4_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_4_9: float32 /* ty=float32 */, %FunctionVar_4_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 512, 4, 4), uint8] {
    %40 = qnn.dequantize(%FunctionVar_4_0, %FunctionVar_4_1, %FunctionVar_4_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/pointwise/0/DequantizeLinear:0:0 */;
    %41 = qnn.dequantize(%FunctionVar_4_3, %FunctionVar_4_4, %FunctionVar_4_5, out_dtype="float32", axis=0) /* ty=Tensor[(512, 256, 1, 1), float32] span=/module/layers/5/pointwise/0/DequantizeLinear_1:0:0 */;
    %42 = nn.conv2d(%40, %41, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Conv:0:0 */;
    %43 = qnn.dequantize(%FunctionVar_4_6, %FunctionVar_4_7, %FunctionVar_4_8, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/5/pointwise/0/DequantizeLinear_2:0:0 */;
    %44 = nn.bias_add(%42, %43) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Conv:0:0 */;
    %45 = nn.relu(%44) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Relu:0:0 */;
    %46 = qnn.quantize(%45, %FunctionVar_4_9, %FunctionVar_4_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/5/pointwise/0/QuantizeLinear:0:0 */;
    cast(%46, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 256, 4, 4), uint8], float32, int32, Tensor[(512, 256, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(512), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 512, 4, 4), uint8] */;
  %159 = %158(%157, 0.00390625f /* ty=float32 span=/module/layers/5/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/5/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][72] /* ty=Tensor[(512, 256, 1, 1), int8] span=/module/layers/5/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][73] /* ty=Tensor[(1), float32] span=/module/layers/5/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][74] /* ty=Tensor[(1), int32] span=/module/layers/5/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][75] /* ty=Tensor[(512), int32] span=/module/layers/5/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][76] /* ty=Tensor[(1), float32] span=/module/layers/5/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][77] /* ty=Tensor[(1), int32] span=/module/layers/5/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/5/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/5/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 512, 4, 4), uint8] */;
  %160 = fn (%FunctionVar_3_0: Tensor[(1, 512, 4, 4), uint8] /* ty=Tensor[(1, 512, 4, 4), uint8] */, %FunctionVar_3_1: float32 /* ty=float32 */, %FunctionVar_3_2: int32 /* ty=int32 */, %FunctionVar_3_3: Tensor[(512, 1, 3, 3), int8] /* ty=Tensor[(512, 1, 3, 3), int8] */, %FunctionVar_3_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_3_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_3_6: Tensor[(512), int32] /* ty=Tensor[(512), int32] */, %FunctionVar_3_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_3_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_3_9: float32 /* ty=float32 */, %FunctionVar_3_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 512, 4, 4), uint8] {
    %33 = qnn.dequantize(%FunctionVar_3_0, %FunctionVar_3_1, %FunctionVar_3_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/DequantizeLinear:0:0 */;
    %34 = qnn.dequantize(%FunctionVar_3_3, %FunctionVar_3_4, %FunctionVar_3_5, out_dtype="float32", axis=0) /* ty=Tensor[(512, 1, 3, 3), float32] span=/module/layers/6/depthwise/0/DequantizeLinear_1:0:0 */;
    %35 = nn.conv2d(%33, %34, padding=[1, 1, 1, 1], groups=512, channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Conv:0:0 */;
    %36 = qnn.dequantize(%FunctionVar_3_6, %FunctionVar_3_7, %FunctionVar_3_8, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/6/depthwise/0/DequantizeLinear_2:0:0 */;
    %37 = nn.bias_add(%35, %36) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Conv:0:0 */;
    %38 = nn.relu(%37) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Relu:0:0 */;
    %39 = qnn.quantize(%38, %FunctionVar_3_9, %FunctionVar_3_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/depthwise/0/QuantizeLinear:0:0 */;
    cast(%39, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 512, 4, 4), uint8], float32, int32, Tensor[(512, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(512), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 512, 4, 4), uint8] */;
  %161 = %160(%159, 0.00390625f /* ty=float32 span=/module/layers/6/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/6/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][78] /* ty=Tensor[(512, 1, 3, 3), int8] span=/module/layers/6/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][79] /* ty=Tensor[(1), float32] span=/module/layers/6/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][80] /* ty=Tensor[(1), int32] span=/module/layers/6/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][81] /* ty=Tensor[(512), int32] span=/module/layers/6/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][82] /* ty=Tensor[(1), float32] span=/module/layers/6/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][83] /* ty=Tensor[(1), int32] span=/module/layers/6/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/6/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/6/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 512, 4, 4), uint8] */;
  %162 = fn (%FunctionVar_2_0: Tensor[(1, 512, 4, 4), uint8] /* ty=Tensor[(1, 512, 4, 4), uint8] */, %FunctionVar_2_1: float32 /* ty=float32 */, %FunctionVar_2_2: int32 /* ty=int32 */, %FunctionVar_2_3: Tensor[(512, 512, 1, 1), int8] /* ty=Tensor[(512, 512, 1, 1), int8] */, %FunctionVar_2_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_2_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_2_6: Tensor[(512), int32] /* ty=Tensor[(512), int32] */, %FunctionVar_2_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_2_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_2_9: float32 /* ty=float32 */, %FunctionVar_2_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 512, 4, 4), uint8] {
    %26 = qnn.dequantize(%FunctionVar_2_0, %FunctionVar_2_1, %FunctionVar_2_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/DequantizeLinear:0:0 */;
    %27 = qnn.dequantize(%FunctionVar_2_3, %FunctionVar_2_4, %FunctionVar_2_5, out_dtype="float32", axis=0) /* ty=Tensor[(512, 512, 1, 1), float32] span=/module/layers/6/pointwise/0/DequantizeLinear_1:0:0 */;
    %28 = nn.conv2d(%26, %27, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Conv:0:0 */;
    %29 = qnn.dequantize(%FunctionVar_2_6, %FunctionVar_2_7, %FunctionVar_2_8, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/6/pointwise/0/DequantizeLinear_2:0:0 */;
    %30 = nn.bias_add(%28, %29) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Conv:0:0 */;
    %31 = nn.relu(%30) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Relu:0:0 */;
    %32 = qnn.quantize(%31, %FunctionVar_2_9, %FunctionVar_2_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/pointwise/0/QuantizeLinear:0:0 */;
    cast(%32, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/7/depthwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 512, 4, 4), uint8], float32, int32, Tensor[(512, 512, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(512), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 512, 4, 4), uint8] */;
  %163 = %162(%161, 0.00390625f /* ty=float32 span=/module/layers/6/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/6/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][84] /* ty=Tensor[(512, 512, 1, 1), int8] span=/module/layers/6/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][85] /* ty=Tensor[(1), float32] span=/module/layers/6/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][86] /* ty=Tensor[(1), int32] span=/module/layers/6/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][87] /* ty=Tensor[(512), int32] span=/module/layers/6/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][88] /* ty=Tensor[(1), float32] span=/module/layers/6/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][89] /* ty=Tensor[(1), int32] span=/module/layers/6/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/6/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/6/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 512, 4, 4), uint8] */;
  %164 = fn (%FunctionVar_1_0: Tensor[(1, 512, 4, 4), uint8] /* ty=Tensor[(1, 512, 4, 4), uint8] */, %FunctionVar_1_1: float32 /* ty=float32 */, %FunctionVar_1_2: int32 /* ty=int32 */, %FunctionVar_1_3: Tensor[(512, 1, 3, 3), int8] /* ty=Tensor[(512, 1, 3, 3), int8] */, %FunctionVar_1_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_1_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_1_6: Tensor[(512), int32] /* ty=Tensor[(512), int32] */, %FunctionVar_1_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_1_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_1_9: float32 /* ty=float32 */, %FunctionVar_1_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 512, 2, 2), uint8] {
    %19 = qnn.dequantize(%FunctionVar_1_0, %FunctionVar_1_1, %FunctionVar_1_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/7/depthwise/0/DequantizeLinear:0:0 */;
    %20 = qnn.dequantize(%FunctionVar_1_3, %FunctionVar_1_4, %FunctionVar_1_5, out_dtype="float32", axis=0) /* ty=Tensor[(512, 1, 3, 3), float32] span=/module/layers/7/depthwise/0/DequantizeLinear_1:0:0 */;
    %21 = nn.conv2d(%19, %20, strides=[2, 2], padding=[1, 1, 1, 1], groups=512, channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Conv:0:0 */;
    %22 = qnn.dequantize(%FunctionVar_1_6, %FunctionVar_1_7, %FunctionVar_1_8, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/7/depthwise/0/DequantizeLinear_2:0:0 */;
    %23 = nn.bias_add(%21, %22) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Conv:0:0 */;
    %24 = nn.relu(%23) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Relu:0:0 */;
    %25 = qnn.quantize(%24, %FunctionVar_1_9, %FunctionVar_1_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 2, 2), uint8] span=/module/layers/7/depthwise/0/QuantizeLinear:0:0 */;
    cast(%25, dtype="uint8") /* ty=Tensor[(1, 512, 2, 2), uint8] span=/module/layers/7/pointwise/0/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 512, 4, 4), uint8], float32, int32, Tensor[(512, 1, 3, 3), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(512), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 512, 2, 2), uint8] */;
  %165 = %164(%163, 0.00390625f /* ty=float32 span=/module/layers/7/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/7/depthwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][90] /* ty=Tensor[(512, 1, 3, 3), int8] span=/module/layers/7/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][91] /* ty=Tensor[(1), float32] span=/module/layers/7/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][92] /* ty=Tensor[(1), int32] span=/module/layers/7/depthwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][93] /* ty=Tensor[(512), int32] span=/module/layers/7/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][94] /* ty=Tensor[(1), float32] span=/module/layers/7/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][95] /* ty=Tensor[(1), int32] span=/module/layers/7/depthwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/7/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/7/depthwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 512, 2, 2), uint8] */;
  %166 = fn (%FunctionVar_0_04: Tensor[(1, 512, 2, 2), uint8] /* ty=Tensor[(1, 512, 2, 2), uint8] */, %FunctionVar_0_14: float32 /* ty=float32 */, %FunctionVar_0_24: int32 /* ty=int32 */, %FunctionVar_0_33: Tensor[(1024, 512, 1, 1), int8] /* ty=Tensor[(1024, 512, 1, 1), int8] */, %FunctionVar_0_41: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_0_51: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_0_61: Tensor[(1024), int32] /* ty=Tensor[(1024), int32] */, %FunctionVar_0_71: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_0_81: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_0_91: float32 /* ty=float32 */, %FunctionVar_0_101: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.conv2d_qnn.dequantize_nn.bias_add_nn.relu_qnn.quantize_cast_", Composite="DLA.qconv2d_relu") -> Tensor[(1, 1024, 2, 2), uint8] {
    %12 = qnn.dequantize(%FunctionVar_0_04, %FunctionVar_0_14, %FunctionVar_0_24, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/pointwise/0/DequantizeLinear:0:0 */;
    %13 = qnn.dequantize(%FunctionVar_0_33, %FunctionVar_0_41, %FunctionVar_0_51, out_dtype="float32", axis=0) /* ty=Tensor[(1024, 512, 1, 1), float32] span=/module/layers/7/pointwise/0/DequantizeLinear_1:0:0 */;
    %14 = nn.conv2d(%12, %13, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Conv:0:0 */;
    %15 = qnn.dequantize(%FunctionVar_0_61, %FunctionVar_0_71, %FunctionVar_0_81, out_dtype="float32", axis=0) /* ty=Tensor[(1024), float32] span=/module/layers/7/pointwise/0/DequantizeLinear_2:0:0 */;
    %16 = nn.bias_add(%14, %15) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Conv:0:0 */;
    %17 = nn.relu(%16) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Relu:0:0 */;
    %18 = qnn.quantize(%17, %FunctionVar_0_91, %FunctionVar_0_101, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024, 2, 2), uint8] span=/module/layers/7/pointwise/0/QuantizeLinear:0:0 */;
    cast(%18, dtype="uint8") /* ty=Tensor[(1, 1024, 2, 2), uint8] span=/module/avgpool/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 512, 2, 2), uint8], float32, int32, Tensor[(1024, 512, 1, 1), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(1024), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 1024, 2, 2), uint8] */;
  %167 = %166(%165, 0.00390625f /* ty=float32 span=/module/layers/7/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/7/pointwise/0/DequantizeLinear:0:0 */, meta[relay.Constant][96] /* ty=Tensor[(1024, 512, 1, 1), int8] span=/module/layers/7/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][97] /* ty=Tensor[(1), float32] span=/module/layers/7/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][98] /* ty=Tensor[(1), int32] span=/module/layers/7/pointwise/0/DequantizeLinear_1:0:0 */, meta[relay.Constant][99] /* ty=Tensor[(1024), int32] span=/module/layers/7/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][100] /* ty=Tensor[(1), float32] span=/module/layers/7/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][101] /* ty=Tensor[(1), int32] span=/module/layers/7/pointwise/0/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/layers/7/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/7/pointwise/0/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 1024, 2, 2), uint8] */;
  %168 = fn (%FunctionVar_0_03: Tensor[(1, 1024, 2, 2), uint8] /* ty=Tensor[(1, 1024, 2, 2), uint8] */, %FunctionVar_0_13: float32 /* ty=float32 */, %FunctionVar_0_23: int32 /* ty=int32 */, %FunctionVar_0_32: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_nn.global_avg_pool2d_qnn.quantize_cast_", Composite="DLA.qglobal_avg_pool2d") -> Tensor[(1, 1024, 1, 1), uint8] {
    %9 = qnn.dequantize(%FunctionVar_0_03, %FunctionVar_0_13, %FunctionVar_0_23, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/avgpool/DequantizeLinear:0:0 */;
    %10 = nn.global_avg_pool2d(%9) /* ty=Tensor[(1, 1024, 1, 1), float32] span=/module/avgpool/GlobalAveragePool:0:0 */;
    %11 = qnn.quantize(%10, %FunctionVar_0_13, %FunctionVar_0_32, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024, 1, 1), uint8] span=/module/avgpool/QuantizeLinear:0:0 */;
    cast(%11, dtype="uint8") /* ty=Tensor[(1, 1024, 1, 1), uint8] span=/module/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 1024, 2, 2), uint8], float32, int32, int32) -> Tensor[(1, 1024, 1, 1), uint8] */;
  %169 = %168(%167, 0.00390625f /* ty=float32 span=/module/avgpool/Constant:0:0 */, 128 /* ty=int32 span=/module/avgpool/DequantizeLinear:0:0 */, 128 /* ty=int32 span=/module/avgpool/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 1024, 1, 1), uint8] */;
  %170 = fn (%FunctionVar_0_02: Tensor[(1, 1024, 1, 1), uint8] /* ty=Tensor[(1, 1024, 1, 1), uint8] */, %FunctionVar_0_12: float32 /* ty=float32 */, %FunctionVar_0_22: int32 /* ty=int32 */, %FunctionVar_0_31: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_nn.batch_flatten_qnn.quantize_cast_", Composite="DLA.flatten") -> Tensor[(1, 1024), uint8] {
    %6 = qnn.dequantize(%FunctionVar_0_02, %FunctionVar_0_12, %FunctionVar_0_22, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024, 1, 1), float32] span=/module/DequantizeLinear:0:0 */;
    %7 = nn.batch_flatten(%6) /* ty=Tensor[(1, 1024), float32] span=/module/Flatten:0:0 */;
    %8 = qnn.quantize(%7, %FunctionVar_0_12, %FunctionVar_0_31, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024), uint8] span=/module/QuantizeLinear:0:0 */;
    cast(%8, dtype="uint8") /* ty=Tensor[(1, 1024), uint8] span=/module/fc/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 1024, 1, 1), uint8], float32, int32, int32) -> Tensor[(1, 1024), uint8] */;
  %171 = %170(%169, 0.00390625f /* ty=float32 span=/module/Constant:0:0 */, 128 /* ty=int32 span=/module/DequantizeLinear:0:0 */, 128 /* ty=int32 span=/module/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 1024), uint8] */;
  %172 = fn (%FunctionVar_0_01: Tensor[(1, 1024), uint8] /* ty=Tensor[(1, 1024), uint8] */, %FunctionVar_0_11: float32 /* ty=float32 */, %FunctionVar_0_21: int32 /* ty=int32 */, %FunctionVar_0_3: Tensor[(10, 1024), int8] /* ty=Tensor[(10, 1024), int8] */, %FunctionVar_0_4: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_0_5: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_0_6: Tensor[(10), int32] /* ty=Tensor[(10), int32] */, %FunctionVar_0_7: Tensor[(1), float32] /* ty=Tensor[(1), float32] */, %FunctionVar_0_8: Tensor[(1), int32] /* ty=Tensor[(1), int32] */, %FunctionVar_0_9: float32 /* ty=float32 */, %FunctionVar_0_10: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_qnn.dequantize_nn.dense_qnn.dequantize_add_qnn.quantize_cast_", Composite="DLA.qlinear") -> Tensor[(1, 10), uint8] {
    %0 = qnn.dequantize(%FunctionVar_0_01, %FunctionVar_0_11, %FunctionVar_0_21, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024), float32] span=/module/fc/DequantizeLinear:0:0 */;
    %1 = qnn.dequantize(%FunctionVar_0_3, %FunctionVar_0_4, %FunctionVar_0_5, out_dtype="float32", axis=0) /* ty=Tensor[(10, 1024), float32] span=/module/fc/DequantizeLinear_1:0:0 */;
    %2 = nn.dense(%0, %1, units=10) /* ty=Tensor[(1, 10), float32] span=/module/fc/Gemm:0:0 */;
    %3 = qnn.dequantize(%FunctionVar_0_6, %FunctionVar_0_7, %FunctionVar_0_8, out_dtype="float32", axis=0) /* ty=Tensor[(10), float32] span=/module/fc/DequantizeLinear_2:0:0 */;
    %4 = add(%2, %3) /* ty=Tensor[(1, 10), float32] span=/module/fc/Gemm:0:0 */;
    %5 = qnn.quantize(%4, %FunctionVar_0_9, %FunctionVar_0_10, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 10), uint8] span=/module/fc/QuantizeLinear:0:0 */;
    cast(%5, dtype="uint8") /* ty=Tensor[(1, 10), uint8] span=/dequant/Cast:0:0 */
  } /* ty=fn (Tensor[(1, 1024), uint8], float32, int32, Tensor[(10, 1024), int8], Tensor[(1), float32], Tensor[(1), int32], Tensor[(10), int32], Tensor[(1), float32], Tensor[(1), int32], float32, int32) -> Tensor[(1, 10), uint8] */;
  %173 = %172(%171, 0.00390625f /* ty=float32 span=/module/fc/Constant:0:0 */, 128 /* ty=int32 span=/module/fc/DequantizeLinear:0:0 */, meta[relay.Constant][102] /* ty=Tensor[(10, 1024), int8] span=/module/fc/Constant_2:0:0 */, meta[relay.Constant][103] /* ty=Tensor[(1), float32] span=/module/fc/Constant_3:0:0 */, meta[relay.Constant][104] /* ty=Tensor[(1), int32] span=/module/fc/DequantizeLinear_1:0:0 */, meta[relay.Constant][105] /* ty=Tensor[(10), int32] span=/module/fc/Constant_6:0:0 */, meta[relay.Constant][106] /* ty=Tensor[(1), float32] span=/module/fc/Constant_7:0:0 */, meta[relay.Constant][107] /* ty=Tensor[(1), int32] span=/module/fc/DequantizeLinear_2:0:0 */, 0.00390625f /* ty=float32 span=/module/fc/Constant_8:0:0 */, 128 /* ty=int32 span=/module/fc/QuantizeLinear:0:0 */) /* ty=Tensor[(1, 10), uint8] */;
  %174 = fn (%FunctionVar_0_0: Tensor[(1, 10), uint8] /* ty=Tensor[(1, 10), uint8] */, %FunctionVar_0_1: float32 /* ty=float32 */, %FunctionVar_0_2: int32 /* ty=int32 */, PartitionedFromPattern="qnn.dequantize_", Composite="DLA.dequantize") -> Tensor[(1, 10), float32] {
    qnn.dequantize(%FunctionVar_0_0, %FunctionVar_0_1, %FunctionVar_0_2, out_dtype="float32", axis=0) /* ty=Tensor[(1, 10), float32] span=/dequant/DequantizeLinear:0:0 */
  } /* ty=fn (Tensor[(1, 10), uint8], float32, int32) -> Tensor[(1, 10), float32] */;
  %174(%173, 0.00390625f /* ty=float32 span=/dequant/Constant:0:0 */, 128 /* ty=int32 span=/dequant/DequantizeLinear:0:0 */) /* ty=Tensor[(1, 10), float32] */
}


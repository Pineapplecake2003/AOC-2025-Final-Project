def @main(%input: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] span=/quant/QuantizeLinear.input:0:0 */) -> Tensor[(1, 10), float32] {
  %0 = qnn.quantize(%input, 0.03125f /* ty=float32 span=/quant/Constant_1:0:0 */, 128 /* ty=int32 span=/quant/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 3, 32, 32), uint8] span=/quant/QuantizeLinear:0:0 */;
  %1 = cast(%0, dtype="uint8") /* ty=Tensor[(1, 3, 32, 32), uint8] span=/module/conv1/0/Cast:0:0 */;
  %2 = qnn.dequantize(%1, 0.03125f /* ty=float32 span=/module/conv1/0/Constant:0:0 */, 128 /* ty=int32 span=/module/conv1/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 3, 32, 32), float32] span=/module/conv1/0/DequantizeLinear:0:0 */;
  %3 = qnn.dequantize(meta[relay.Constant][0] /* ty=Tensor[(32, 3, 3, 3), int8] span=/module/conv1/0/Constant_2:0:0 */, meta[relay.Constant][1] /* ty=Tensor[(1), float32] span=/module/conv1/0/Constant_3:0:0 */, meta[relay.Constant][2] /* ty=Tensor[(1), int32] span=/module/conv1/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32, 3, 3, 3), float32] span=/module/conv1/0/DequantizeLinear_1:0:0 */;
  %4 = nn.conv2d(%2, %3, padding=[1, 1, 1, 1], channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Conv:0:0 */;
  %5 = qnn.dequantize(meta[relay.Constant][3] /* ty=Tensor[(32), int32] span=/module/conv1/0/Constant_6:0:0 */, meta[relay.Constant][4] /* ty=Tensor[(1), float32] span=/module/conv1/0/Constant_7:0:0 */, meta[relay.Constant][5] /* ty=Tensor[(1), int32] span=/module/conv1/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=/module/conv1/0/DequantizeLinear_2:0:0 */;
  %6 = nn.bias_add(%4, %5) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Conv:0:0 */;
  %7 = nn.relu(%6) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/conv1/0/Relu:0:0 */;
  %8 = qnn.quantize(%7, 0.015625f /* ty=float32 span=/module/conv1/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/conv1/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/conv1/0/QuantizeLinear:0:0 */;
  %9 = cast(%8, dtype="uint8") /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/depthwise/0/Cast:0:0 */;
  %10 = qnn.dequantize(%9, 0.015625f /* ty=float32 span=/module/layers/0/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/0/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/DequantizeLinear:0:0 */;
  %11 = qnn.dequantize(meta[relay.Constant][6] /* ty=Tensor[(32, 1, 3, 3), int8] span=/module/layers/0/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][7] /* ty=Tensor[(1), float32] span=/module/layers/0/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][8] /* ty=Tensor[(1), int32] span=/module/layers/0/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32, 1, 3, 3), float32] span=/module/layers/0/depthwise/0/DequantizeLinear_1:0:0 */;
  %12 = nn.conv2d(%10, %11, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Conv:0:0 */;
  %13 = qnn.dequantize(meta[relay.Constant][9] /* ty=Tensor[(32), int32] span=/module/layers/0/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][10] /* ty=Tensor[(1), float32] span=/module/layers/0/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][11] /* ty=Tensor[(1), int32] span=/module/layers/0/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(32), float32] span=/module/layers/0/depthwise/0/DequantizeLinear_2:0:0 */;
  %14 = nn.bias_add(%12, %13) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Conv:0:0 */;
  %15 = nn.relu(%14) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/depthwise/0/Relu:0:0 */;
  %16 = qnn.quantize(%15, 0.0078125f /* ty=float32 span=/module/layers/0/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/0/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/depthwise/0/QuantizeLinear:0:0 */;
  %17 = cast(%16, dtype="uint8") /* ty=Tensor[(1, 32, 32, 32), uint8] span=/module/layers/0/pointwise/0/Cast:0:0 */;
  %18 = qnn.dequantize(%17, 0.0078125f /* ty=float32 span=/module/layers/0/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/0/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 32, 32, 32), float32] span=/module/layers/0/pointwise/0/DequantizeLinear:0:0 */;
  %19 = qnn.dequantize(meta[relay.Constant][12] /* ty=Tensor[(64, 32, 1, 1), int8] span=/module/layers/0/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][13] /* ty=Tensor[(1), float32] span=/module/layers/0/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][14] /* ty=Tensor[(1), int32] span=/module/layers/0/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64, 32, 1, 1), float32] span=/module/layers/0/pointwise/0/DequantizeLinear_1:0:0 */;
  %20 = nn.conv2d(%18, %19, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1]) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Conv:0:0 */;
  %21 = qnn.dequantize(meta[relay.Constant][15] /* ty=Tensor[(64), int32] span=/module/layers/0/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][16] /* ty=Tensor[(1), float32] span=/module/layers/0/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][17] /* ty=Tensor[(1), int32] span=/module/layers/0/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=/module/layers/0/pointwise/0/DequantizeLinear_2:0:0 */;
  %22 = nn.bias_add(%20, %21) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Conv:0:0 */;
  %23 = nn.relu(%22) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/0/pointwise/0/Relu:0:0 */;
  %24 = qnn.quantize(%23, 0.00390625f /* ty=float32 span=/module/layers/0/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/0/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 64, 32, 32), uint8] span=/module/layers/0/pointwise/0/QuantizeLinear:0:0 */;
  %25 = cast(%24, dtype="uint8") /* ty=Tensor[(1, 64, 32, 32), uint8] span=/module/layers/1/depthwise/0/Cast:0:0 */;
  %26 = qnn.dequantize(%25, 0.00390625f /* ty=float32 span=/module/layers/1/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/1/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 64, 32, 32), float32] span=/module/layers/1/depthwise/0/DequantizeLinear:0:0 */;
  %27 = qnn.dequantize(meta[relay.Constant][18] /* ty=Tensor[(64, 1, 3, 3), int8] span=/module/layers/1/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][19] /* ty=Tensor[(1), float32] span=/module/layers/1/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][20] /* ty=Tensor[(1), int32] span=/module/layers/1/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64, 1, 3, 3), float32] span=/module/layers/1/depthwise/0/DequantizeLinear_1:0:0 */;
  %28 = nn.conv2d(%26, %27, strides=[2, 2], padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Conv:0:0 */;
  %29 = qnn.dequantize(meta[relay.Constant][21] /* ty=Tensor[(64), int32] span=/module/layers/1/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][22] /* ty=Tensor[(1), float32] span=/module/layers/1/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][23] /* ty=Tensor[(1), int32] span=/module/layers/1/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(64), float32] span=/module/layers/1/depthwise/0/DequantizeLinear_2:0:0 */;
  %30 = nn.bias_add(%28, %29) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Conv:0:0 */;
  %31 = nn.relu(%30) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/depthwise/0/Relu:0:0 */;
  %32 = qnn.quantize(%31, 0.00390625f /* ty=float32 span=/module/layers/1/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/1/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 64, 16, 16), uint8] span=/module/layers/1/depthwise/0/QuantizeLinear:0:0 */;
  %33 = cast(%32, dtype="uint8") /* ty=Tensor[(1, 64, 16, 16), uint8] span=/module/layers/1/pointwise/0/Cast:0:0 */;
  %34 = qnn.dequantize(%33, 0.00390625f /* ty=float32 span=/module/layers/1/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/1/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 64, 16, 16), float32] span=/module/layers/1/pointwise/0/DequantizeLinear:0:0 */;
  %35 = qnn.dequantize(meta[relay.Constant][24] /* ty=Tensor[(128, 64, 1, 1), int8] span=/module/layers/1/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][25] /* ty=Tensor[(1), float32] span=/module/layers/1/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][26] /* ty=Tensor[(1), int32] span=/module/layers/1/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128, 64, 1, 1), float32] span=/module/layers/1/pointwise/0/DequantizeLinear_1:0:0 */;
  %36 = nn.conv2d(%34, %35, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Conv:0:0 */;
  %37 = qnn.dequantize(meta[relay.Constant][27] /* ty=Tensor[(128), int32] span=/module/layers/1/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][28] /* ty=Tensor[(1), float32] span=/module/layers/1/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][29] /* ty=Tensor[(1), int32] span=/module/layers/1/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/1/pointwise/0/DequantizeLinear_2:0:0 */;
  %38 = nn.bias_add(%36, %37) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Conv:0:0 */;
  %39 = nn.relu(%38) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/1/pointwise/0/Relu:0:0 */;
  %40 = qnn.quantize(%39, 0.00390625f /* ty=float32 span=/module/layers/1/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/1/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/1/pointwise/0/QuantizeLinear:0:0 */;
  %41 = cast(%40, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/depthwise/0/Cast:0:0 */;
  %42 = qnn.dequantize(%41, 0.00390625f /* ty=float32 span=/module/layers/2/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/2/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/DequantizeLinear:0:0 */;
  %43 = qnn.dequantize(meta[relay.Constant][30] /* ty=Tensor[(128, 1, 3, 3), int8] span=/module/layers/2/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][31] /* ty=Tensor[(1), float32] span=/module/layers/2/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][32] /* ty=Tensor[(1), int32] span=/module/layers/2/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128, 1, 3, 3), float32] span=/module/layers/2/depthwise/0/DequantizeLinear_1:0:0 */;
  %44 = nn.conv2d(%42, %43, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Conv:0:0 */;
  %45 = qnn.dequantize(meta[relay.Constant][33] /* ty=Tensor[(128), int32] span=/module/layers/2/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][34] /* ty=Tensor[(1), float32] span=/module/layers/2/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][35] /* ty=Tensor[(1), int32] span=/module/layers/2/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/2/depthwise/0/DequantizeLinear_2:0:0 */;
  %46 = nn.bias_add(%44, %45) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Conv:0:0 */;
  %47 = nn.relu(%46) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/depthwise/0/Relu:0:0 */;
  %48 = qnn.quantize(%47, 0.00390625f /* ty=float32 span=/module/layers/2/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/2/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/depthwise/0/QuantizeLinear:0:0 */;
  %49 = cast(%48, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/pointwise/0/Cast:0:0 */;
  %50 = qnn.dequantize(%49, 0.00390625f /* ty=float32 span=/module/layers/2/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/2/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/DequantizeLinear:0:0 */;
  %51 = qnn.dequantize(meta[relay.Constant][36] /* ty=Tensor[(128, 128, 1, 1), int8] span=/module/layers/2/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][37] /* ty=Tensor[(1), float32] span=/module/layers/2/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][38] /* ty=Tensor[(1), int32] span=/module/layers/2/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128, 128, 1, 1), float32] span=/module/layers/2/pointwise/0/DequantizeLinear_1:0:0 */;
  %52 = nn.conv2d(%50, %51, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1]) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Conv:0:0 */;
  %53 = qnn.dequantize(meta[relay.Constant][39] /* ty=Tensor[(128), int32] span=/module/layers/2/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][40] /* ty=Tensor[(1), float32] span=/module/layers/2/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][41] /* ty=Tensor[(1), int32] span=/module/layers/2/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/2/pointwise/0/DequantizeLinear_2:0:0 */;
  %54 = nn.bias_add(%52, %53) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Conv:0:0 */;
  %55 = nn.relu(%54) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/2/pointwise/0/Relu:0:0 */;
  %56 = qnn.quantize(%55, 0.00390625f /* ty=float32 span=/module/layers/2/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/2/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/2/pointwise/0/QuantizeLinear:0:0 */;
  %57 = cast(%56, dtype="uint8") /* ty=Tensor[(1, 128, 16, 16), uint8] span=/module/layers/3/depthwise/0/Cast:0:0 */;
  %58 = qnn.dequantize(%57, 0.00390625f /* ty=float32 span=/module/layers/3/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/3/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 16, 16), float32] span=/module/layers/3/depthwise/0/DequantizeLinear:0:0 */;
  %59 = qnn.dequantize(meta[relay.Constant][42] /* ty=Tensor[(128, 1, 3, 3), int8] span=/module/layers/3/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][43] /* ty=Tensor[(1), float32] span=/module/layers/3/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][44] /* ty=Tensor[(1), int32] span=/module/layers/3/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128, 1, 3, 3), float32] span=/module/layers/3/depthwise/0/DequantizeLinear_1:0:0 */;
  %60 = nn.conv2d(%58, %59, strides=[2, 2], padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3]) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Conv:0:0 */;
  %61 = qnn.dequantize(meta[relay.Constant][45] /* ty=Tensor[(128), int32] span=/module/layers/3/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][46] /* ty=Tensor[(1), float32] span=/module/layers/3/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][47] /* ty=Tensor[(1), int32] span=/module/layers/3/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(128), float32] span=/module/layers/3/depthwise/0/DequantizeLinear_2:0:0 */;
  %62 = nn.bias_add(%60, %61) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Conv:0:0 */;
  %63 = nn.relu(%62) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/depthwise/0/Relu:0:0 */;
  %64 = qnn.quantize(%63, 0.00390625f /* ty=float32 span=/module/layers/3/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/3/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 128, 8, 8), uint8] span=/module/layers/3/depthwise/0/QuantizeLinear:0:0 */;
  %65 = cast(%64, dtype="uint8") /* ty=Tensor[(1, 128, 8, 8), uint8] span=/module/layers/3/pointwise/0/Cast:0:0 */;
  %66 = qnn.dequantize(%65, 0.00390625f /* ty=float32 span=/module/layers/3/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/3/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 128, 8, 8), float32] span=/module/layers/3/pointwise/0/DequantizeLinear:0:0 */;
  %67 = qnn.dequantize(meta[relay.Constant][48] /* ty=Tensor[(256, 128, 1, 1), int8] span=/module/layers/3/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][49] /* ty=Tensor[(1), float32] span=/module/layers/3/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][50] /* ty=Tensor[(1), int32] span=/module/layers/3/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256, 128, 1, 1), float32] span=/module/layers/3/pointwise/0/DequantizeLinear_1:0:0 */;
  %68 = nn.conv2d(%66, %67, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Conv:0:0 */;
  %69 = qnn.dequantize(meta[relay.Constant][51] /* ty=Tensor[(256), int32] span=/module/layers/3/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][52] /* ty=Tensor[(1), float32] span=/module/layers/3/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][53] /* ty=Tensor[(1), int32] span=/module/layers/3/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/3/pointwise/0/DequantizeLinear_2:0:0 */;
  %70 = nn.bias_add(%68, %69) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Conv:0:0 */;
  %71 = nn.relu(%70) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/3/pointwise/0/Relu:0:0 */;
  %72 = qnn.quantize(%71, 0.00390625f /* ty=float32 span=/module/layers/3/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/3/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/3/pointwise/0/QuantizeLinear:0:0 */;
  %73 = cast(%72, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/depthwise/0/Cast:0:0 */;
  %74 = qnn.dequantize(%73, 0.00390625f /* ty=float32 span=/module/layers/4/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/4/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/DequantizeLinear:0:0 */;
  %75 = qnn.dequantize(meta[relay.Constant][54] /* ty=Tensor[(256, 1, 3, 3), int8] span=/module/layers/4/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][55] /* ty=Tensor[(1), float32] span=/module/layers/4/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][56] /* ty=Tensor[(1), int32] span=/module/layers/4/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256, 1, 3, 3), float32] span=/module/layers/4/depthwise/0/DequantizeLinear_1:0:0 */;
  %76 = nn.conv2d(%74, %75, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Conv:0:0 */;
  %77 = qnn.dequantize(meta[relay.Constant][57] /* ty=Tensor[(256), int32] span=/module/layers/4/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][58] /* ty=Tensor[(1), float32] span=/module/layers/4/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][59] /* ty=Tensor[(1), int32] span=/module/layers/4/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/4/depthwise/0/DequantizeLinear_2:0:0 */;
  %78 = nn.bias_add(%76, %77) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Conv:0:0 */;
  %79 = nn.relu(%78) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/depthwise/0/Relu:0:0 */;
  %80 = qnn.quantize(%79, 0.00390625f /* ty=float32 span=/module/layers/4/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/4/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/depthwise/0/QuantizeLinear:0:0 */;
  %81 = cast(%80, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/pointwise/0/Cast:0:0 */;
  %82 = qnn.dequantize(%81, 0.00390625f /* ty=float32 span=/module/layers/4/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/4/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/DequantizeLinear:0:0 */;
  %83 = qnn.dequantize(meta[relay.Constant][60] /* ty=Tensor[(256, 256, 1, 1), int8] span=/module/layers/4/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][61] /* ty=Tensor[(1), float32] span=/module/layers/4/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][62] /* ty=Tensor[(1), int32] span=/module/layers/4/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256, 256, 1, 1), float32] span=/module/layers/4/pointwise/0/DequantizeLinear_1:0:0 */;
  %84 = nn.conv2d(%82, %83, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1]) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Conv:0:0 */;
  %85 = qnn.dequantize(meta[relay.Constant][63] /* ty=Tensor[(256), int32] span=/module/layers/4/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][64] /* ty=Tensor[(1), float32] span=/module/layers/4/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][65] /* ty=Tensor[(1), int32] span=/module/layers/4/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/4/pointwise/0/DequantizeLinear_2:0:0 */;
  %86 = nn.bias_add(%84, %85) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Conv:0:0 */;
  %87 = nn.relu(%86) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/4/pointwise/0/Relu:0:0 */;
  %88 = qnn.quantize(%87, 0.00390625f /* ty=float32 span=/module/layers/4/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/4/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/4/pointwise/0/QuantizeLinear:0:0 */;
  %89 = cast(%88, dtype="uint8") /* ty=Tensor[(1, 256, 8, 8), uint8] span=/module/layers/5/depthwise/0/Cast:0:0 */;
  %90 = qnn.dequantize(%89, 0.00390625f /* ty=float32 span=/module/layers/5/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/5/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 8, 8), float32] span=/module/layers/5/depthwise/0/DequantizeLinear:0:0 */;
  %91 = qnn.dequantize(meta[relay.Constant][66] /* ty=Tensor[(256, 1, 3, 3), int8] span=/module/layers/5/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][67] /* ty=Tensor[(1), float32] span=/module/layers/5/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][68] /* ty=Tensor[(1), int32] span=/module/layers/5/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256, 1, 3, 3), float32] span=/module/layers/5/depthwise/0/DequantizeLinear_1:0:0 */;
  %92 = nn.conv2d(%90, %91, strides=[2, 2], padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3]) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Conv:0:0 */;
  %93 = qnn.dequantize(meta[relay.Constant][69] /* ty=Tensor[(256), int32] span=/module/layers/5/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][70] /* ty=Tensor[(1), float32] span=/module/layers/5/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][71] /* ty=Tensor[(1), int32] span=/module/layers/5/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(256), float32] span=/module/layers/5/depthwise/0/DequantizeLinear_2:0:0 */;
  %94 = nn.bias_add(%92, %93) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Conv:0:0 */;
  %95 = nn.relu(%94) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/depthwise/0/Relu:0:0 */;
  %96 = qnn.quantize(%95, 0.00390625f /* ty=float32 span=/module/layers/5/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/5/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 256, 4, 4), uint8] span=/module/layers/5/depthwise/0/QuantizeLinear:0:0 */;
  %97 = cast(%96, dtype="uint8") /* ty=Tensor[(1, 256, 4, 4), uint8] span=/module/layers/5/pointwise/0/Cast:0:0 */;
  %98 = qnn.dequantize(%97, 0.00390625f /* ty=float32 span=/module/layers/5/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/5/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 256, 4, 4), float32] span=/module/layers/5/pointwise/0/DequantizeLinear:0:0 */;
  %99 = qnn.dequantize(meta[relay.Constant][72] /* ty=Tensor[(512, 256, 1, 1), int8] span=/module/layers/5/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][73] /* ty=Tensor[(1), float32] span=/module/layers/5/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][74] /* ty=Tensor[(1), int32] span=/module/layers/5/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512, 256, 1, 1), float32] span=/module/layers/5/pointwise/0/DequantizeLinear_1:0:0 */;
  %100 = nn.conv2d(%98, %99, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Conv:0:0 */;
  %101 = qnn.dequantize(meta[relay.Constant][75] /* ty=Tensor[(512), int32] span=/module/layers/5/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][76] /* ty=Tensor[(1), float32] span=/module/layers/5/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][77] /* ty=Tensor[(1), int32] span=/module/layers/5/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/5/pointwise/0/DequantizeLinear_2:0:0 */;
  %102 = nn.bias_add(%100, %101) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Conv:0:0 */;
  %103 = nn.relu(%102) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/5/pointwise/0/Relu:0:0 */;
  %104 = qnn.quantize(%103, 0.00390625f /* ty=float32 span=/module/layers/5/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/5/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/5/pointwise/0/QuantizeLinear:0:0 */;
  %105 = cast(%104, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/depthwise/0/Cast:0:0 */;
  %106 = qnn.dequantize(%105, 0.00390625f /* ty=float32 span=/module/layers/6/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/6/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/DequantizeLinear:0:0 */;
  %107 = qnn.dequantize(meta[relay.Constant][78] /* ty=Tensor[(512, 1, 3, 3), int8] span=/module/layers/6/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][79] /* ty=Tensor[(1), float32] span=/module/layers/6/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][80] /* ty=Tensor[(1), int32] span=/module/layers/6/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512, 1, 3, 3), float32] span=/module/layers/6/depthwise/0/DequantizeLinear_1:0:0 */;
  %108 = nn.conv2d(%106, %107, padding=[1, 1, 1, 1], groups=512, channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Conv:0:0 */;
  %109 = qnn.dequantize(meta[relay.Constant][81] /* ty=Tensor[(512), int32] span=/module/layers/6/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][82] /* ty=Tensor[(1), float32] span=/module/layers/6/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][83] /* ty=Tensor[(1), int32] span=/module/layers/6/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/6/depthwise/0/DequantizeLinear_2:0:0 */;
  %110 = nn.bias_add(%108, %109) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Conv:0:0 */;
  %111 = nn.relu(%110) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/depthwise/0/Relu:0:0 */;
  %112 = qnn.quantize(%111, 0.00390625f /* ty=float32 span=/module/layers/6/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/6/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/depthwise/0/QuantizeLinear:0:0 */;
  %113 = cast(%112, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/pointwise/0/Cast:0:0 */;
  %114 = qnn.dequantize(%113, 0.00390625f /* ty=float32 span=/module/layers/6/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/6/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/DequantizeLinear:0:0 */;
  %115 = qnn.dequantize(meta[relay.Constant][84] /* ty=Tensor[(512, 512, 1, 1), int8] span=/module/layers/6/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][85] /* ty=Tensor[(1), float32] span=/module/layers/6/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][86] /* ty=Tensor[(1), int32] span=/module/layers/6/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512, 512, 1, 1), float32] span=/module/layers/6/pointwise/0/DequantizeLinear_1:0:0 */;
  %116 = nn.conv2d(%114, %115, padding=[0, 0, 0, 0], channels=512, kernel_size=[1, 1]) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Conv:0:0 */;
  %117 = qnn.dequantize(meta[relay.Constant][87] /* ty=Tensor[(512), int32] span=/module/layers/6/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][88] /* ty=Tensor[(1), float32] span=/module/layers/6/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][89] /* ty=Tensor[(1), int32] span=/module/layers/6/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/6/pointwise/0/DequantizeLinear_2:0:0 */;
  %118 = nn.bias_add(%116, %117) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Conv:0:0 */;
  %119 = nn.relu(%118) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/6/pointwise/0/Relu:0:0 */;
  %120 = qnn.quantize(%119, 0.00390625f /* ty=float32 span=/module/layers/6/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/6/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/6/pointwise/0/QuantizeLinear:0:0 */;
  %121 = cast(%120, dtype="uint8") /* ty=Tensor[(1, 512, 4, 4), uint8] span=/module/layers/7/depthwise/0/Cast:0:0 */;
  %122 = qnn.dequantize(%121, 0.00390625f /* ty=float32 span=/module/layers/7/depthwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/7/depthwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 4, 4), float32] span=/module/layers/7/depthwise/0/DequantizeLinear:0:0 */;
  %123 = qnn.dequantize(meta[relay.Constant][90] /* ty=Tensor[(512, 1, 3, 3), int8] span=/module/layers/7/depthwise/0/Constant_2:0:0 */, meta[relay.Constant][91] /* ty=Tensor[(1), float32] span=/module/layers/7/depthwise/0/Constant_3:0:0 */, meta[relay.Constant][92] /* ty=Tensor[(1), int32] span=/module/layers/7/depthwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512, 1, 3, 3), float32] span=/module/layers/7/depthwise/0/DequantizeLinear_1:0:0 */;
  %124 = nn.conv2d(%122, %123, strides=[2, 2], padding=[1, 1, 1, 1], groups=512, channels=512, kernel_size=[3, 3]) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Conv:0:0 */;
  %125 = qnn.dequantize(meta[relay.Constant][93] /* ty=Tensor[(512), int32] span=/module/layers/7/depthwise/0/Constant_6:0:0 */, meta[relay.Constant][94] /* ty=Tensor[(1), float32] span=/module/layers/7/depthwise/0/Constant_7:0:0 */, meta[relay.Constant][95] /* ty=Tensor[(1), int32] span=/module/layers/7/depthwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(512), float32] span=/module/layers/7/depthwise/0/DequantizeLinear_2:0:0 */;
  %126 = nn.bias_add(%124, %125) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Conv:0:0 */;
  %127 = nn.relu(%126) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/depthwise/0/Relu:0:0 */;
  %128 = qnn.quantize(%127, 0.00390625f /* ty=float32 span=/module/layers/7/depthwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/7/depthwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 512, 2, 2), uint8] span=/module/layers/7/depthwise/0/QuantizeLinear:0:0 */;
  %129 = cast(%128, dtype="uint8") /* ty=Tensor[(1, 512, 2, 2), uint8] span=/module/layers/7/pointwise/0/Cast:0:0 */;
  %130 = qnn.dequantize(%129, 0.00390625f /* ty=float32 span=/module/layers/7/pointwise/0/Constant:0:0 */, 128 /* ty=int32 span=/module/layers/7/pointwise/0/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 512, 2, 2), float32] span=/module/layers/7/pointwise/0/DequantizeLinear:0:0 */;
  %131 = qnn.dequantize(meta[relay.Constant][96] /* ty=Tensor[(1024, 512, 1, 1), int8] span=/module/layers/7/pointwise/0/Constant_2:0:0 */, meta[relay.Constant][97] /* ty=Tensor[(1), float32] span=/module/layers/7/pointwise/0/Constant_3:0:0 */, meta[relay.Constant][98] /* ty=Tensor[(1), int32] span=/module/layers/7/pointwise/0/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1024, 512, 1, 1), float32] span=/module/layers/7/pointwise/0/DequantizeLinear_1:0:0 */;
  %132 = nn.conv2d(%130, %131, padding=[0, 0, 0, 0], channels=1024, kernel_size=[1, 1]) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Conv:0:0 */;
  %133 = qnn.dequantize(meta[relay.Constant][99] /* ty=Tensor[(1024), int32] span=/module/layers/7/pointwise/0/Constant_6:0:0 */, meta[relay.Constant][100] /* ty=Tensor[(1), float32] span=/module/layers/7/pointwise/0/Constant_7:0:0 */, meta[relay.Constant][101] /* ty=Tensor[(1), int32] span=/module/layers/7/pointwise/0/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1024), float32] span=/module/layers/7/pointwise/0/DequantizeLinear_2:0:0 */;
  %134 = nn.bias_add(%132, %133) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Conv:0:0 */;
  %135 = nn.relu(%134) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/layers/7/pointwise/0/Relu:0:0 */;
  %136 = qnn.quantize(%135, 0.00390625f /* ty=float32 span=/module/layers/7/pointwise/0/Constant_8:0:0 */, 128 /* ty=int32 span=/module/layers/7/pointwise/0/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024, 2, 2), uint8] span=/module/layers/7/pointwise/0/QuantizeLinear:0:0 */;
  %137 = cast(%136, dtype="uint8") /* ty=Tensor[(1, 1024, 2, 2), uint8] span=/module/avgpool/Cast:0:0 */;
  %138 = qnn.dequantize(%137, 0.00390625f /* ty=float32 span=/module/avgpool/Constant:0:0 */, 128 /* ty=int32 span=/module/avgpool/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024, 2, 2), float32] span=/module/avgpool/DequantizeLinear:0:0 */;
  %139 = nn.global_avg_pool2d(%138) /* ty=Tensor[(1, 1024, 1, 1), float32] span=/module/avgpool/GlobalAveragePool:0:0 */;
  %140 = qnn.quantize(%139, 0.00390625f /* ty=float32 span=/module/avgpool/Constant:0:0 */, 128 /* ty=int32 span=/module/avgpool/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024, 1, 1), uint8] span=/module/avgpool/QuantizeLinear:0:0 */;
  %141 = cast(%140, dtype="uint8") /* ty=Tensor[(1, 1024, 1, 1), uint8] span=/module/Cast:0:0 */;
  %142 = qnn.dequantize(%141, 0.00390625f /* ty=float32 span=/module/Constant:0:0 */, 128 /* ty=int32 span=/module/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024, 1, 1), float32] span=/module/DequantizeLinear:0:0 */;
  %143 = nn.batch_flatten(%142) /* ty=Tensor[(1, 1024), float32] span=/module/Flatten:0:0 */;
  %144 = qnn.quantize(%143, 0.00390625f /* ty=float32 span=/module/Constant:0:0 */, 128 /* ty=int32 span=/module/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 1024), uint8] span=/module/QuantizeLinear:0:0 */;
  %145 = cast(%144, dtype="uint8") /* ty=Tensor[(1, 1024), uint8] span=/module/fc/Cast:0:0 */;
  %146 = qnn.dequantize(%145, 0.00390625f /* ty=float32 span=/module/fc/Constant:0:0 */, 128 /* ty=int32 span=/module/fc/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 1024), float32] span=/module/fc/DequantizeLinear:0:0 */;
  %147 = qnn.dequantize(meta[relay.Constant][102] /* ty=Tensor[(10, 1024), int8] span=/module/fc/Constant_2:0:0 */, meta[relay.Constant][103] /* ty=Tensor[(1), float32] span=/module/fc/Constant_3:0:0 */, meta[relay.Constant][104] /* ty=Tensor[(1), int32] span=/module/fc/DequantizeLinear_1:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(10, 1024), float32] span=/module/fc/DequantizeLinear_1:0:0 */;
  %148 = nn.dense(%146, %147, units=10) /* ty=Tensor[(1, 10), float32] span=/module/fc/Gemm:0:0 */;
  %149 = qnn.dequantize(meta[relay.Constant][105] /* ty=Tensor[(10), int32] span=/module/fc/Constant_6:0:0 */, meta[relay.Constant][106] /* ty=Tensor[(1), float32] span=/module/fc/Constant_7:0:0 */, meta[relay.Constant][107] /* ty=Tensor[(1), int32] span=/module/fc/DequantizeLinear_2:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(10), float32] span=/module/fc/DequantizeLinear_2:0:0 */;
  %150 = add(%148, %149) /* ty=Tensor[(1, 10), float32] span=/module/fc/Gemm:0:0 */;
  %151 = qnn.quantize(%150, 0.00390625f /* ty=float32 span=/module/fc/Constant_8:0:0 */, 128 /* ty=int32 span=/module/fc/QuantizeLinear:0:0 */, out_dtype="uint8", axis=0) /* ty=Tensor[(1, 10), uint8] span=/module/fc/QuantizeLinear:0:0 */;
  %152 = cast(%151, dtype="uint8") /* ty=Tensor[(1, 10), uint8] span=/dequant/Cast:0:0 */;
  qnn.dequantize(%152, 0.00390625f /* ty=float32 span=/dequant/Constant:0:0 */, 128 /* ty=int32 span=/dequant/DequantizeLinear:0:0 */, out_dtype="float32", axis=0) /* ty=Tensor[(1, 10), float32] span=/dequant/DequantizeLinear:0:0 */
}

